{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping,CSVLogger\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from datetime import datetime\n",
    "\n",
    "#This is the basic model using unresized 200x300 images. These settings produced the model with the best abnormal call accuracy\n",
    "\n",
    "#Variables to edit-----------------\n",
    "epochs=500                #Number of epochs for training\n",
    "filenameprefix = 'CNN200x300ep'+str(epochs) #Start of filename that will be used in last saved model after training\n",
    "\n",
    "learningrate = 0.0005  #Learning rate for optimizer if used for adam optimizer\n",
    "\n",
    "espatience = 30          #tensorboard Earlystop function patience value --Use if EarlyStopping is used\n",
    "#End of variables to edit----------\n",
    "filename = filenameprefix + str(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "#Tensorboard functions\n",
    "tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "checkpointvacc  = ModelCheckpoint('weights/{epoch:02d}.h5'\n",
    "                             , monitor='val_acc', mode='max', save_best_only=True)\n",
    "checkpointvloss  = ModelCheckpoint('weights/{epoch:02d}.h5'\n",
    "                             , monitor='val_loss', mode='min', save_best_only=True)\n",
    "checkpointloss  = ModelCheckpoint('weights/{epoch:02d}.h5'\n",
    "                             , monitor='loss', mode='min', save_best_only=True)\n",
    "earlystop   = EarlyStopping(monitor='val_acc', patience=espatience, mode='auto', verbose=1)\n",
    "csv_logger = CSVLogger(filename+'training.csv', separator=',')\n",
    "\n",
    "\n",
    "train_data = ImageDataGenerator(rescale=1./255)\n",
    "test_data = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#End of tensorboard functions\n",
    "train_generator = train_data.flow_from_directory('../images/train',batch_size=40,class_mode='binary',target_size=(200,300))\n",
    "test_generator = test_data.flow_from_directory('../images/test',batch_size=32,class_mode='binary',target_size=(200,300))\n",
    "label_map = (train_generator.class_indices)#Stores classes and their values. Can be displayed on screen if needed\n",
    "\n",
    "#Model Layers-Layers represent the factors of 200 & 300 for easier calculations\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (5, 5), strides=5, input_shape=(200, 300, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(128, (5, 5), strides=5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))      \n",
    "model.add(Flatten())\n",
    "model.add(Dense(768, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#End of Model layers------------------------------------------------------------\n",
    "#adam = optimizers.adam(lr=learningrate) #Adam was used in testing most of the time but sgd produced the best results at the end\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "history=model.fit_generator( train_generator,\n",
    "        steps_per_epoch=60,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=20, callbacks=[checkpointvacc,checkpointvloss])#Add tensorboard functions here\n",
    "        \n",
    "\n",
    "#model.summary() #Displays the model structure\n",
    "filename = filenameprefix + str(datetime.now().strftime('%Y%m%d-%H%M%S')) #Get time and date now to add to filename\n",
    "model.save('weights/%s.h5' % filename) #Save model\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Plot training & validation accuracy values by history saved-doesn't use tensorboard\n",
    "plt.figure(1,figsize=(10,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(2,figsize=(10,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "#Testing code \n",
    "#This program reads models from a folder (example: Those saved by Modelcheckpoint in tensorboard) and runs predictions on a\n",
    "#folder(s) of images. Output displays the # of results from the cutoff to 1 individually and the % of the results at that cutoff \n",
    "imageheight=200\n",
    "imagewidth=300\n",
    "cutoff=0.7 #Above this value is an echolcation + below is abnormal file-Used for displaying the min. cutoff to calculate from\n",
    "mfolder = \"./weights/\" #Folder with saved models in h5 format\n",
    "ifolder = \"../abcopy/a/\" #Folder with images to test model with\n",
    "foldercheck2 = True #Do you want to check the 2nd folder of images?\n",
    "ifolder2 = \"../images/train/echolocation/\" #Folder2 with images to test model with\n",
    "foldercheck3 = False #Do you want to check the 3rd folder of images?\n",
    "ifolder3 = \"../abcopy/a/\" #Folder3 with images to test model with\n",
    "mincheck = 200 #Min starting model which represents the epoch that it was created-Models below this will be deleted from folder\n",
    "\n",
    "modcount=0 #Counts the model number for display purposes\n",
    "for mdl in range(mincheck+1): #Remove unwanted models less than this variable\n",
    "    if os.path.exists(mfolder+str(mdl)+\".h5\"):\n",
    "        os.remove(mfolder+str(mdl)+\".h5\")\n",
    "    if os.path.exists(mfolder+\"0\"+str(mdl)+\".h5\"):\n",
    "        os.remove(mfolder+\"0\"+str(mdl)+\".h5\")   \n",
    "print('Reading directories from model and image folders')\n",
    "mfilelist = os.listdir(mfolder) #Make list of model filenames\n",
    "ifilelist = os.listdir(ifolder) #Make list of image filenames\n",
    "if foldercheck2 == True:\n",
    "    ifilelist2 = os.listdir(ifolder2) #Make list of image filenames for 2nd scan\n",
    "if foldercheck3 == True:\n",
    "    ifilelist3 = os.listdir(ifolder3) #Make list of image filenames for 3rd scan\n",
    "for ipremove in mfilelist: #Remove .ipynb_checkpoints folder which may get saved in models folder\n",
    "    if '{}'.format(ipremove[0:6]) == '.ipynb':\n",
    "        shutil.rmtree(mfolder+ipremove)\n",
    "mfilelist = os.listdir(mfolder) #Make list of model filenames again if .ipynb_checkpoints existed before \n",
    "print('Processing {0:2d} images in {1:2d} models-------------------------'.format(len(ifilelist),len(mfilelist)))\n",
    "cutoffdiff = int((1-cutoff)*10) #Calculates the difference between the cutoff and 1-Used for calculating & displaying accuracies\n",
    "for mdl in range(len(mfilelist)):\n",
    "    modcount += 1\n",
    "    model = load_model(mfolder+mfilelist[mdl])\n",
    "    #model.summary() #Displays model layers and info\n",
    "    abcount = [0] * cutoffdiff \n",
    "    for inum in range(len(ifilelist)):\n",
    "        image = load_img(ifolder + ifilelist[inum], target_size=(imageheight,imagewidth))\n",
    "        imageresize = image.resize((imagewidth, imageheight)) #Resize image for desired CNN model\n",
    "        imagearray = img_to_array(imageresize) #Make image into an array\n",
    "        imagearray = np.expand_dims(imagearray, 0) #Add 4th dimension to array for CNN -> will get error otherwise\n",
    "        imagearray = imagearray.astype('float32')/255 #Convert array so that its predictions are readable\n",
    "        prediction=model.predict(imagearray) #Run prediction on image-Returns list of float predictions\n",
    "        for abdetermine in range(cutoffdiff):\n",
    "            if prediction[0]<(cutoff+(abdetermine*0.1)):\n",
    "                abcount[abdetermine]=abcount[abdetermine]+1\n",
    "    print('{0:2d}. of {1:2d} Model: {2:s}'.format(modcount,len(mfilelist),mfilelist[mdl]))\n",
    "    for abprint in range(cutoffdiff):\n",
    "        print('Abnormal @ cutoff {0:2.1f}: {1:2d} at {2:4.2f}% Echolocation count: {3:2d} at {4:4.2f}%'.format(cutoff+(abprint*0.1),\n",
    "        abcount[abprint],abcount[abprint]*100/len(ifilelist),(len(ifilelist)-abcount[abprint]),             \n",
    "        (len(ifilelist)-abcount[abprint])*100/len(ifilelist)))\n",
    "    if foldercheck2 == True:\n",
    "        #print('Processing {0:2d} images in each model'.format(len(ifilelist2)))\n",
    "        abcount = [0] * cutoffdiff\n",
    "        for inum in range(len(ifilelist2)):\n",
    "            image = load_img(ifolder2 + ifilelist2[inum], target_size=(imageheight,imagewidth))\n",
    "            imageresize = image.resize((imagewidth, imageheight)) #Resize image for desired CNN model\n",
    "            imagearray = img_to_array(imageresize) #Make image into an array\n",
    "            imagearray = np.expand_dims(imagearray, 0) #Add 4th dimension to array for CNN -> will get error otherwise\n",
    "            imagearray = imagearray.astype('float32')/255 #Convert array so that its predictions are readable\n",
    "            prediction=model.predict(imagearray) #Run prediction on image-Returns list of float predictions\n",
    "            for abdetermine in range(cutoffdiff):\n",
    "                if prediction[0]<(cutoff+(abdetermine*0.1)):\n",
    "                    abcount[abdetermine]=abcount[abdetermine]+1\n",
    "        print('Folder 2 results:')\n",
    "        for abprint in range(cutoffdiff):\n",
    "            print('Abnormal @ cutoff {0:2.1f}: {1:2d} at {2:4.2f}% Echolocation count: {3:2d} at {4:4.2f}%'.format(cutoff+(abprint*0.1),\n",
    "            abcount[abprint],abcount[abprint]*100/len(ifilelist2),(len(ifilelist2)-abcount[abprint]),             \n",
    "            (len(ifilelist2)-abcount[abprint])*100/len(ifilelist2)))\n",
    "    if foldercheck3 == True:\n",
    "        #print('Processing {0:2d} images in each model'.format(len(ifilelist3)))\n",
    "        abcount = [0] * cutoffdiff\n",
    "        for inum in range(len(ifilelist3)):\n",
    "            image = load_img(ifolder3 + ifilelist3[inum], target_size=(imageheight,imagewidth))\n",
    "            imageresize = image.resize((imagewidth, imageheight)) #Resize image for desired CNN model\n",
    "            imagearray = img_to_array(imageresize) #Make image into an array\n",
    "            imagearray = np.expand_dims(imagearray, 0) #Add 4th dimension to array for CNN -> will get error otherwise\n",
    "            imagearray = imagearray.astype('float32')/255 #Convert array so that its predictions are readable\n",
    "            prediction=model.predict(imagearray) #Run prediction on image-Returns list of float predictions\n",
    "            for abdetermine in range(cutoffdiff):\n",
    "                if prediction[0]<(cutoff+(abdetermine*0.1)):\n",
    "                    abcount[abdetermine]=abcount[abdetermine]+1\n",
    "        print('Folder 3 results:')\n",
    "        for abprint in range(cutoffdiff):\n",
    "            print('Abnormal @ cutoff {0:2.1f}: {1:2d} at {2:4.2f}% Echolocation count: {3:2d} at {4:4.2f}%'.format(cutoff+(abprint*0.1),\n",
    "            abcount[abprint],abcount[abprint]*100/len(ifilelist3),(len(ifilelist3)-abcount[abprint]),             \n",
    "            (len(ifilelist3)-abcount[abprint])*100/len(ifilelist3)))\n",
    "    print('End of model {0:s} predictions-----------------------'.format(mfilelist[mdl]))\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
